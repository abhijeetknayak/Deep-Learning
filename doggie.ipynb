{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, exists, expanduser\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras import optimizers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dogBreed/\"\n",
    "\n",
    "train = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "# print(train.head())\n",
    "\n",
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img1 = image.load_img(data_dir + '/train/' + train['id'][i]+'.jpg', target_size=(224,224,3))\n",
    "    img = image.img_to_array(img1) / 255\n",
    "    train_image.append(img)\n",
    "X = np.array(train_image)\n",
    "print(X.shape)\n",
    "\n",
    "y = train['breed'].values\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y_trans = le.transform(y)\n",
    "\n",
    "y_final = to_categorical(y_trans)\n",
    "print(y_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_final, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=96,kernel_size=(11,11),input_shape=(224,224,3),strides=(4,4), padding='valid',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding='valid',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='valid',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding='valid',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='valid',kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096,input_shape=(224*224*3,),kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(4096, kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(120, activation='softmax', kernel_initializer='random_uniform',bias_initializer='zeros'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.SGD(lr=0.01, momentum=0.9, decay=5e-3)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = X_train.shape[0]\n",
    "# mini_batch_size = 100\n",
    "# num_iter = 100\n",
    "# num_mini_batches = m // mini_batch_size\n",
    "# print(m, num_mini_batches)\n",
    "# for i in tqdm(range(num_iter)):\n",
    "#     for j in (range(num_mini_batches)):\n",
    "#         mini_Xtrain = X_train[j*mini_batch_size:(j+1)*mini_batch_size,]\n",
    "#         mini_ytrain = y_train[j*mini_batch_size:(j+1)*mini_batch_size,]\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resmodel = Sequential()\n",
    "weights_path = \"../keras-pretrained-models/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "resmodel.add(ResNet50(include_top=False, pooling='avg', weights=weights_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./dogBreed\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Activation, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.read_csv('./dogBreed/labels.csv')\n",
    "testdf=pd.read_csv('./dogBreed/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(13, 6))\n",
    "traindf['breed'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_percentages(labels):\n",
    "    class_map={}\n",
    "    for i in labels:\n",
    "        if str(i) not in class_map:\n",
    "            class_map[str(i)]=1\n",
    "        else:\n",
    "            class_map[str(i)]+=1\n",
    "    #     print(class_map)\n",
    "    return class_map\n",
    "\n",
    "p=class_percentages(traindf.breed.values)\n",
    "# print(p)\n",
    "# for i in p.items():\n",
    "#     print(i)\n",
    "\n",
    "print(\"Class with maximum images-\"+str(max(p, key=p.get))+\"  \"+str(p[max(p, key=p.get)]))\n",
    "print(\"Class with maximum images-\"+str(min(p,key=p.get)) +\"  \"+str(p[min(p, key=p.get)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 120\n",
    "resnet_weights_path = \"../Keras-Pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(512))\n",
    "my_new_model.add(Activation('relu'))\n",
    "my_new_model.add(Dropout(0.5))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "my_new_model.layers[0].trainable = False\n",
    "\n",
    "my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input, \n",
    "                             rescale=1./255.,\n",
    "                             horizontal_flip=True,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "                        dataframe=traindf,\n",
    "                        directory=\"./dogBreed/train/\",\n",
    "                        x_col=\"id\",\n",
    "                        y_col=\"breed\",\n",
    "                        has_ext=False,\n",
    "                        subset=\"training\",\n",
    "                        batch_size=32,\n",
    "                        seed=50,\n",
    "                        shuffle=True,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "                        dataframe=traindf,\n",
    "                        directory=\"./dogBreed/train/\",\n",
    "                        x_col=\"id\",\n",
    "                        y_col=\"breed\",\n",
    "                        has_ext=False,\n",
    "                        subset=\"validation\",\n",
    "                        batch_size=1,\n",
    "                        seed=42,\n",
    "                        shuffle=True,\n",
    "                        class_mode=\"categorical\",\n",
    "                        target_size=(image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,rescale=1./255.)\n",
    "\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "                            dataframe=testdf,\n",
    "                            directory=\"./dogBreed/test/\",\n",
    "                            x_col=\"id\",\n",
    "                            y_col=None,\n",
    "                            has_ext=False,\n",
    "                            batch_size=1,\n",
    "                            seed=42,\n",
    "                            shuffle=False,\n",
    "                            class_mode=None,\n",
    "                            target_size=(image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n\n",
    "STEP_SIZE_VALID=valid_generator.n\n",
    "\n",
    "print(STEP_SIZE_TRAIN)\n",
    "print(STEP_SIZE_VALID)\n",
    "\n",
    "my_new_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
